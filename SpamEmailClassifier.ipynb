{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpamEmailClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAGGLKxgnNxg"
      },
      "source": [
        "**Spam Email Classifier**\r\n",
        "\r\n",
        "Task :\r\n",
        "Build a classification model which will be able to distinguish between spam/not spam. You should\r\n",
        "compare the performance of few classification algorithms by your choice and choose the best\r\n",
        "performing one. You should perform k-fold cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y4StkPgoXIC",
        "outputId": "39ff8912-43af-4225-fd50-190069418d6d"
      },
      "source": [
        "#All the necessary imports used throughout the file.\r\n",
        "!pip install PyDrive\r\n",
        "from pydrive.auth import GoogleAuth\r\n",
        "from pydrive.drive import GoogleDrive\r\n",
        "from google.colab import auth\r\n",
        "from oauth2client.client import GoogleCredentials\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn import model_selection\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.neural_network import MLPClassifier\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (1.7.12)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.7.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.17.4)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (1.15.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (53.0.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (4.2.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt30APyCdqtD"
      },
      "source": [
        "#Authentication required for Google colab files. Note that we are reading data files(datasets) from the drive and hence there is a GoogleDrive depencdency.\r\n",
        "auth.authenticate_user()\r\n",
        "gauth = GoogleAuth()\r\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\r\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT7NxQg-ra_j"
      },
      "source": [
        "**DataSet Details:**\r\n",
        "The last column of 'spambase.data' denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail. Most of the attributes indicate whether a particular word or character was frequently occuring in the e-mail. The run-length attributes (55-57) measure the length of sequences of consecutive capital letters. For the statistical measures of each attribute, see the end of this file. Here are the definitions of the attributes:\r\n",
        "\r\n",
        "48 continuous real [0,100] attributes of type word_freq_WORD\r\n",
        "= percentage of words in the e-mail that match WORD, i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail. A \"word\" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string.\r\n",
        "\r\n",
        "6 continuous real [0,100] attributes of type char_freq_CHAR]\r\n",
        "= percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail\r\n",
        "\r\n",
        "1 continuous real [1,...] attribute of type capital_run_length_average\r\n",
        "= average length of uninterrupted sequences of capital letters\r\n",
        "\r\n",
        "1 continuous integer [1,...] attribute of type capital_run_length_longest\r\n",
        "= length of longest uninterrupted sequence of capital letters\r\n",
        "\r\n",
        "1 continuous integer [1,...] attribute of type capital_run_length_total\r\n",
        "= sum of length of uninterrupted sequences of capital letters\r\n",
        "= total number of capital letters in the e-mail\r\n",
        "\r\n",
        "1 nominal {0,1} class attribute of type spam\r\n",
        "= denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Lcq6YHXdv5y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b5714e5-5c98-4894-c44a-83b381771a03"
      },
      "source": [
        "#Code to download the dataset and convert it into dataframe.\r\n",
        "downloaded = drive.CreateFile({'id':\"12IhRv4WkpMyCYicnsJVeKxuVk0co6E5s\"})   # replace the id with id of file you want to access\r\n",
        "downloaded.GetContentFile('spambase.data')\r\n",
        "\r\n",
        "downloadedc = drive.CreateFile({'id':\"1g-rZgD7Bg_Hzh3sMZaqLf1AQIcvhXhIp\"})   # replace the id with id of file you want to access\r\n",
        "downloadedc.GetContentFile('spambase.names')\r\n",
        "\r\n",
        "f = open('spambase.names','r')\r\n",
        "count = 0\r\n",
        "columns = []\r\n",
        "while(True):\r\n",
        "  line = f.readline()\r\n",
        "  if(line):\r\n",
        "    count += 1\r\n",
        "    if(count>=34):\r\n",
        "      columns.append(line.split(\":\")[0]) \r\n",
        "  else:\r\n",
        "    break\r\n",
        "columns.append('spam')\r\n",
        "#print(columns) \r\n",
        "data = pd.read_csv('spambase.data')\r\n",
        "df = pd.DataFrame(data)\r\n",
        "df.columns = columns\r\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      word_freq_make  word_freq_address  ...  capital_run_length_total  spam\n",
            "0               0.21               0.28  ...                      1028     1\n",
            "1               0.06               0.00  ...                      2259     1\n",
            "2               0.00               0.00  ...                       191     1\n",
            "3               0.00               0.00  ...                       191     1\n",
            "4               0.00               0.00  ...                        54     1\n",
            "...              ...                ...  ...                       ...   ...\n",
            "4595            0.31               0.00  ...                        88     0\n",
            "4596            0.00               0.00  ...                        14     0\n",
            "4597            0.30               0.00  ...                       118     0\n",
            "4598            0.96               0.00  ...                        78     0\n",
            "4599            0.00               0.00  ...                        40     0\n",
            "\n",
            "[4600 rows x 58 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwpqSldSrkFk"
      },
      "source": [
        "**Classifiers detail : ** Note: Few parameters have been fine tuned for better performance results.\r\n",
        "1. LogisticRegression - We will use lbfgs solver with 2000 iterations\r\n",
        "2. KNeighborsClassifier - we are using Euclidean metrics with 4 neighbours to classify the given predict data point.\r\n",
        "3. SVC - we are using rbf kernal for this classification\r\n",
        "4. MultinomialNB - alpha value has been fine tuned to 1 for getting better resutls and fit_prior is made true.\r\n",
        "5. RandomForestClassifier - Using 50 estimators with maxdepth of decision trees set to 50\r\n",
        "6. MLPClassifier - Neural Network approach for solving the problem. Fine tuned a parameters for better results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQkZ8LZdd1Ro",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "outputId": "d53e171c-ebc6-464c-e8be-fd8f701fb6e4"
      },
      "source": [
        "X = df.drop(['spam'],axis=1).values\r\n",
        "y = df['spam'].values\r\n",
        "\r\n",
        "classifiers = [\r\n",
        "               LogisticRegression(solver = \"lbfgs\",max_iter = 2000),\r\n",
        "               KNeighborsClassifier(n_neighbors = 4, metric = 'euclidean', p = 2),\r\n",
        "               SVC(kernel = 'rbf',gamma='auto'),\r\n",
        "               MultinomialNB(alpha=1.0,fit_prior=True),\r\n",
        "               RandomForestClassifier(n_estimators=50,max_depth=50),\r\n",
        "               MLPClassifier(solver='adam',activation='relu', alpha=1e-8,hidden_layer_sizes=(12, 5, 5),learning_rate = 'constant', learning_rate_init=0.0001, max_iter=2000)\r\n",
        "            ]\r\n",
        "names = [\"LogisticRegression\",\"KNeighborsClassifier\",\"SVC\",\"MultinomialNB\",\"RandomForestClassifier\",\"MLPClassifier\"]\r\n",
        "results = []\r\n",
        "kfold = 10\r\n",
        "seed = 7\r\n",
        "best_auc = -1\r\n",
        "for i in range(0,len(classifiers)):\r\n",
        "  classifier = classifiers[i]\r\n",
        "  total_auc = 0\r\n",
        "  kfold_result = []\r\n",
        "  kf = model_selection.KFold(n_splits=kfold, shuffle= True,random_state=seed)\r\n",
        "  for train_index, test_index in kf.split(X):\r\n",
        "    X_train, X_test = X[train_index], X[test_index] \r\n",
        "    y_train, y_test = y[train_index], y[test_index]\r\n",
        "\r\n",
        "    classifier.fit(X_train,y_train)\r\n",
        "    predict_y = classifier.predict(X_test)\r\n",
        "    auc = roc_auc_score(y_test,predict_y)\r\n",
        "    kfold_result.append(auc)\r\n",
        "    total_auc += auc\r\n",
        "  mean_auc_kfolds = total_auc/kfold\r\n",
        "  results.append(kfold_result)\r\n",
        "  if best_auc<mean_auc_kfolds:\r\n",
        "    best_auc = mean_auc_kfolds\r\n",
        "    bestalgo = names[i]\r\n",
        "    index = i\r\n",
        "print(results)\r\n",
        "print(names)\r\n",
        "# boxplot algorithm comparison\r\n",
        "fig = plt.figure(figsize=(20,10))\r\n",
        "fig.suptitle('Algorithm Comparison')\r\n",
        "ax = fig.add_subplot(111)\r\n",
        "plt.boxplot(results)\r\n",
        "ax.set_xticklabels(names)\r\n",
        "plt.show()\r\n",
        "\r\n",
        "print(bestalgo,best_auc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.9235710332832635, 0.9299154083326744, 0.9136538461538461, 0.9358006773101113, 0.9127120026092629, 0.9058788291917126, 0.9264267818744946, 0.9190291183552884, 0.9172356957852602, 0.93540991382718], [0.7974938730334414, 0.7683216064511028, 0.8115384615384615, 0.7746976294146105, 0.7632093933463796, 0.7682138356984983, 0.7717642185003255, 0.7825026811550212, 0.7867514323836432, 0.7820578701873665], [0.8662740137560282, 0.8118230690173137, 0.8428846153846155, 0.8604257377842284, 0.8217547292889759, 0.8294499184069736, 0.8230455110374623, 0.8215362512394018, 0.8410839023624519, 0.8411929796821883], [0.7704166337259862, 0.7952407304925291, 0.8063461538461538, 0.7403483309143687, 0.7706294846705806, 0.7951085497097767, 0.7686472943915094, 0.7888362775450738, 0.7728200298249744, 0.7736579966795795], [0.9571902917226658, 0.9397580836429756, 0.9615384615384616, 0.946589259796807, 0.9403946510110893, 0.9446716655305614, 0.951845495255568, 0.9457597280398228, 0.9521819323444, 0.949798403035813], [0.9344612222310064, 0.9254684164756107, 0.9286538461538462, 0.946734397677794, 0.9067596216568818, 0.9354692115428312, 0.9255982324278471, 0.7467775551913232, 0.9403696727101484, 0.9318127915250216]]\n",
            "['LogisticRegression', 'KNeighborsClassifier', 'SVC', 'MultinomialNB', 'RandomForestClassifier', 'MLPClassifier']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier 0.9489727971918163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6qUFHGex_xj"
      },
      "source": [
        "**Inference from comparision** \r\n",
        "We could infere that RandomForestClassifier works the best for given set of inputs. But if we look closely, LogisticRegression, MLP and RandomForestClassifier all the 3 are performing pretty well.If we can more fine tune the paramters or increase the dataset size, we may end up getting more better results in any of the 3 algorithms. In MLP neural network based classifier we can see there are few outliers which can be retrained and we can get more better results. For KNN, SVC and multinomial, we can infere that this classifiers dont work well with contiguous data. The boxplot shows some skew in the distribution of data for this classifiers. Since RandomForestClassifier gave the best results, lets get confusion matrix and print the required table for the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuKyfFA4sLyp"
      },
      "source": [
        "**Confusion matrix and details with KFold cross validation for the best performing model**\r\n",
        "\r\n",
        "KFold Cross Validation ensures that we wont overfit the model.\r\n",
        "\r\n",
        "1.  False positive rate - Fraction of non-spam testing examples that are misclassified as spam\r\n",
        "2.  False negative rate - Fraction of spam testing examples that are misclassified as non-spam\r\n",
        "3.  Overall error rate - Fraction of overall examples that are misclassified.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "j3ilz2oQHs_-",
        "outputId": "80606820-748a-43f2-c927-d36db22a6259"
      },
      "source": [
        "total_false_positive = 0\r\n",
        "total_false_negative = 0\r\n",
        "total_error = 0 \r\n",
        "average_false_positive = 0\r\n",
        "average_false_negative = 0 \r\n",
        "avg_error = 0\r\n",
        "fp = []\r\n",
        "fn = []\r\n",
        "overall_error_rate = []\r\n",
        "\r\n",
        "classifier = classifiers[index]\r\n",
        "for train_index, test_index in kf.split(X):\r\n",
        "  X_train, X_test = X[train_index], X[test_index] \r\n",
        "  y_train, y_test = y[train_index], y[test_index]\r\n",
        "\r\n",
        "  classifier.fit(X_train,y_train)\r\n",
        "  predict_y = classifier.predict(X_test)\r\n",
        "  matrix = confusion_matrix(y_test,predict_y)\r\n",
        "  false_positive_rate = matrix[0][1]/(matrix[0][1] + matrix[0][0])\r\n",
        "  false_negative_rate = matrix[1][0]/(matrix[1][0] + matrix[1][1])\r\n",
        "  fp.append(false_positive_rate)\r\n",
        "  fn.append(false_negative_rate)\r\n",
        "  overall_error_rate.append(1 - accuracy_score(y_test,predict_y))\r\n",
        "  total_false_negative += false_negative_rate\r\n",
        "  total_false_positive += false_positive_rate\r\n",
        "  total_error += 1 - accuracy_score(y_test,predict_y)    \r\n",
        "\r\n",
        "average_false_positive = total_false_positive/kfold\r\n",
        "average_false_negative = total_false_negative/kfold\r\n",
        "avg_error = total_error/kfold\r\n",
        "\r\n",
        "\r\n",
        "Table = pd.DataFrame(list(zip(fp,fn,overall_error_rate)),columns = ['False Positive Rate','False Negative Rate','Overall Error Rate'])\r\n",
        "Table.loc[kfold] = [average_false_positive,average_false_negative,avg_error]\r\n",
        "display(Table)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "      <th>Overall Error Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.017986</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.039130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.028777</td>\n",
              "      <td>0.087912</td>\n",
              "      <td>0.052174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.026923</td>\n",
              "      <td>0.055000</td>\n",
              "      <td>0.039130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.052830</td>\n",
              "      <td>0.046154</td>\n",
              "      <td>0.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.013699</td>\n",
              "      <td>0.119048</td>\n",
              "      <td>0.052174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.040404</td>\n",
              "      <td>0.067485</td>\n",
              "      <td>0.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.018051</td>\n",
              "      <td>0.060109</td>\n",
              "      <td>0.034783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.027682</td>\n",
              "      <td>0.081871</td>\n",
              "      <td>0.047826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.032847</td>\n",
              "      <td>0.059140</td>\n",
              "      <td>0.043478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.017986</td>\n",
              "      <td>0.082418</td>\n",
              "      <td>0.043478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.027718</td>\n",
              "      <td>0.073056</td>\n",
              "      <td>0.045217</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    False Positive Rate  False Negative Rate  Overall Error Rate\n",
              "0              0.017986             0.071429            0.039130\n",
              "1              0.028777             0.087912            0.052174\n",
              "2              0.026923             0.055000            0.039130\n",
              "3              0.052830             0.046154            0.050000\n",
              "4              0.013699             0.119048            0.052174\n",
              "5              0.040404             0.067485            0.050000\n",
              "6              0.018051             0.060109            0.034783\n",
              "7              0.027682             0.081871            0.047826\n",
              "8              0.032847             0.059140            0.043478\n",
              "9              0.017986             0.082418            0.043478\n",
              "10             0.027718             0.073056            0.045217"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}